@InProceedings{lopez-paz_2018_RevisitingClassifierTwoSample,
  author        = {Lopez{-}Paz, David and Oquab, Maxime},
  title         = {Revisiting {{Classifier Two-Sample Tests}}},
  booktitle     = {5th International Conference on Learning Representations, {ICLR}},
  year          = {2017},
  eprint        = {1610.06545},
  eprinttype    = {arxiv},
  url           = {http://arxiv.org/abs/1610.06545},
  abstract      = {The goal of two-sample tests is to assess whether two samples, \$S\_P \textbackslash sim P\^n\$ and \$S\_Q \textbackslash sim Q\^m\$, are drawn from the same distribution. Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the \$n\$ examples in \$S\_P\$ with a positive label, and by pairing the \$m\$ examples in \$S\_Q\$ with a negative label. If the null hypothesis "\$P = Q\$" is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level. As we will show, such Classifier Two-Sample Tests (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where \$P\$ and \$Q\$ differ. The goal of this paper is to establish the properties, performance, and uses of C2ST. First, we analyze their main theoretical properties. Second, we compare their performance against a variety of state-of-the-art alternatives. Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs). Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.},
  archiveprefix = {arXiv},
  file          = {files/papers/Lopez-Paz and Oquab - 2018 - Revisiting Classifier Two-Sample Tests.pdf;/home/elcorto/.zotero/storage/JC8DU68C/1610.html},
  keywords      = {c2st},
}

@Online{daxberger_2021_LaplaceReduxEffortless,
  author        = {Daxberger, Erik and Kristiadi, Agustinus and Immer, Alexander and Eschenhagen, Runa and Bauer, Matthias and Hennig, Philipp},
  title         = {Laplace {{Redux}} -- {{Effortless Bayesian Deep Learning}}},
  date          = {2021-10-30},
  url           = {http://arxiv.org/abs/2106.14806},
  abstract      = {Bayesian formulations of deep learning have been shown to have compelling theoretical properties and offer practical functional benefits, such as improved predictive uncertainty quantification and model selection. The Laplace approximation (LA) is a classic, and arguably the simplest family of approximations for the intractable posteriors of deep neural networks. Yet, despite its simplicity, the LA is not as popular as alternatives like variational Bayes or deep ensembles. This may be due to assumptions that the LA is expensive due to the involved Hessian computation, that it is difficult to implement, or that it yields inferior results. In this work we show that these are misconceptions: we (i) review the range of variants of the LA including versions with minimal cost overhead; (ii) introduce "laplace", an easy-to-use software library for PyTorch offering user-friendly access to all major flavors of the LA; and (iii) demonstrate through extensive experiments that the LA is competitive with more popular alternatives in terms of performance, while excelling in terms of computational cost. We hope that this work will serve as a catalyst to a wider adoption of the LA in practical deep learning, including in domains where Bayesian approaches are not typically considered at the moment.},
  archiveprefix = {arXiv},
  eprint        = {2106.14806},
  eprinttype    = {arxiv},
  file          = {files/papers/Daxberger et al. - 2021 - Laplace Redux -- Effortless Bayesian Deep Learning.pdf;/home/elcorto/Zotero/storage/NIEGWC6W/2106.html},
  keywords      = {laplace},
}

@Article{steinbach_2022_MachineLearningStateoftheArt,
  author        = {Steinbach, Peter and Gernhardt, Felicita and Tanveer, Mahnoor and Schmerler, Steve and Starke, Sebastian},
  title         = {Machine {{Learning State-of-the-Art}} with {{Uncertainties}}},
  journal       = {ICLR},
  year          = {2022},
  date          = {2022-04-14},
  doi           = {10.48550/arXiv.2204.05173},
  eprint        = {2204.05173},
  eprinttype    = {arxiv},
  url           = {http://arxiv.org/abs/2204.05173},
  abstract      = {With the availability of data, hardware, software ecosystem and relevant skill sets, the machine learning community is undergoing a rapid development with new architectures and approaches appearing at high frequency every year. In this article, we conduct an exemplary image classification study in order to demonstrate how confidence intervals around accuracy measurements can greatly enhance the communication of research results as well as impact the reviewing process. In addition, we explore the hallmarks and limitations of this approximation. We discuss the relevance of this approach reflecting on a spotlight publication of ICLR22. A reproducible workflow is made available as an open-source adjoint to this publication. Based on our discussion, we make suggestions for improving the authoring and reviewing process of machine learning articles.},
  archiveprefix = {arXiv},
  file          = {/home/elcorto/.zotero/storage/57JS9259/Steinbach et al. - 2022 - Machine Learning State-of-the-Art with Uncertainti.pdf;/home/elcorto/.zotero/storage/YBPHBC86/2204.html},
  primaryclass  = {cs},
  publisher     = {{arXiv}},
}

@inproceedings{stardist_schmidt_2018,
  author    = {Uwe Schmidt and Martin Weigert and Coleman Broaddus and Gene Myers},
  title     = {Cell Detection with Star-Convex Polygons},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}},
  pages     = {265--273},
  year      = {2018},
  doi       = {10.1007/978-3-030-00934-2_30}
}

@Online{raschka_2018_ModelEvaluationModel,
  author        = {Raschka, Sebastian},
  title         = {Model {{Evaluation}}, {{Model Selection}}, and {{Algorithm Selection}} in {{Machine Learning}}},
  year          = {2018},
%%  date          = {2020-11-10},
  url           = {http://arxiv.org/abs/1811.12808},
%%  urldate       = {2022-02-07},
  abstract      = {The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.},
  archiveprefix = {arXiv},
  eprint        = {1811.12808},
  eprinttype    = {arxiv},
  file          = {files/papers/Raschka - 2020 - Model Evaluation, Model Selection, and Algorithm S.pdf;/home/elcorto/.zotero/storage/LG5MFN88/1811.html},
  keywords      = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass  = {cs, stat},
}
